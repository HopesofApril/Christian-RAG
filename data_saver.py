import os
import faiss
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OllamaEmbeddings
from langchain.docstore.in_memory import InMemoryDocstore
from langchain.text_splitter import RecursiveCharacterTextSplitter
from data_loader import HWPLoader
import hashlib

# === ì„¤ì • ===
EMBEDDING_MODEL = "nomic-embed-text"
VECTORSTORE_DIR = "./vectorstore"
INDEX_NAME = "faiss_index"

# === ì„ë² ë”© ëª¨ë¸ ===
embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)


def build_vectorstore_from_dir(document_dir: str):
    """ì§€ì •ëœ í´ë”ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ì½ì–´ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸"""
    # ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” (ì—†ìœ¼ë©´ ìƒì„±)
    if not os.path.exists(f"{VECTORSTORE_DIR}/{INDEX_NAME}.faiss"):
        if not os.path.exists(VECTORSTORE_DIR):
            os.mkdir(VECTORSTORE_DIR)
        dim = len(embeddings.embed_query("hello world"))
        vectorstore = FAISS(
            embedding_function=embeddings,
            index=faiss.IndexFlatL2(dim),
            docstore=InMemoryDocstore(),
            index_to_docstore_id={},
        )
    else:
        vectorstore = FAISS.load_local(
            folder_path=VECTORSTORE_DIR,
            index_name=INDEX_NAME,
            embeddings=embeddings,
            allow_dangerous_deserialization=True,
        )

    # ë””ë ‰í† ë¦¬ ë‚´ ë¬¸ì„œ ìˆœíšŒ
    for filename in os.listdir(document_dir):
        if not filename.lower().endswith(".hwp"):
            continue

        print(f"... ğŸ“„ {filename} ì§„í–‰ì¤‘ ...")

        file_path = os.path.join(document_dir, filename)
        file_hash = hashlib.md5(open(file_path, 'rb').read()).hexdigest()

        try:
            loader = HWPLoader(file_path)
            docs = loader.load()
        except Exception as e:
            print(f"âš ï¸  {filename} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ â†’ ê±´ë„ˆëœë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
            continue  # ë‹¤ìŒ íŒŒì¼ë¡œ ë„˜ì–´ê°

        # ë¬¸ì„œ ë¡œë“œ ë° ë©”íƒ€ë°ì´í„° ì„¤ì •
        # loader = HWPLoader(file_path)
        # docs = loader.load()
        
        for doc in docs:
            doc.metadata["file_hash"] = file_hash
            doc.metadata["file_name"] = filename

        # ë¬¸ì„œ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
        split_docs = text_splitter.split_documents(docs)

        # ë¬¸ì„œ ë²¡í„°í™” ë° ì¶”ê°€
        vectorstore.add_documents(split_docs, embeddings=embeddings)
        print(f"ğŸ“„ {filename} ë²¡í„°í™” ë° ì €ì¥ ì™„ë£Œ!")

    # ìµœì¢… ì €ì¥
    vectorstore.save_local(folder_path=VECTORSTORE_DIR, index_name=INDEX_NAME)
    print(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: {VECTORSTORE_DIR}/{INDEX_NAME}.faiss")


# === í´ë” ì§€ì • í›„ ì‹¤í–‰ ===
if __name__ == "__main__":
    document_dir = "./2008ë…„"
    build_vectorstore_from_dir(document_dir)
